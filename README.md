# zlatyfond

How well can overparametrized transformers able to model the Classics of Slovak literature?



TODO:
1. linear attention
2. Pipeline paralelism
3. efficiency tricks ala megatron
4.  fixed positional embedings
5. rotary embeddings
6. configure sparsity
7. add data
8. transfer some multilingual knowledge
9. just a better readme
